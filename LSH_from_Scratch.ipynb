{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MoC1_sYwUJzk"
   },
   "source": [
    "#Reading the data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2KTfPxdTihj",
    "outputId": "e07ff0b1-3ce6-4732-8fd4-5e3a2032070c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at gdrive/; to attempt to forcibly remount, call drive.mount(\"gdrive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Code to mount google drive in case you are loading the data from your google drive\n",
    "from google.colab import drive\n",
    "drive.mount(\"gdrive/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "4ITF3UoyaqUj",
    "outputId": "d1fbfe29-ce2f-4f31-e1b3-dace21ffc774"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>NaN</td>\n",
       "      <td>cars pull down us retail figures us retail sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>NaN</td>\n",
       "      <td>kilroy unveils immigration policy ex-chatshow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>NaN</td>\n",
       "      <td>rem announce new glasgow concert us band rem h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>NaN</td>\n",
       "      <td>how political squabbles snowball it s become c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>NaN</td>\n",
       "      <td>souness delight at euro progress boss graeme s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           category                                               text\n",
       "0              tech  tv future in the hands of viewers with home th...\n",
       "1          business  worldcom boss  left books alone  former worldc...\n",
       "2             sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3             sport  yeading face newcastle in fa cup premiership s...\n",
       "4     entertainment  ocean s twelve raids box office ocean s twelve...\n",
       "...             ...                                                ...\n",
       "2220            NaN  cars pull down us retail figures us retail sal...\n",
       "2221            NaN  kilroy unveils immigration policy ex-chatshow ...\n",
       "2222            NaN  rem announce new glasgow concert us band rem h...\n",
       "2223            NaN  how political squabbles snowball it s become c...\n",
       "2224            NaN  souness delight at euro progress boss graeme s...\n",
       "\n",
       "[2225 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data from csv file\n",
    "import pandas as pd\n",
    "data_path = \"gdrive/My Drive/MY_DB/\"\n",
    "df = pd.read_csv(data_path + \"lsh_assignment_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VB0ekaKmbcBW",
    "outputId": "99992b83-fe77-4616-cbf8-47983c6fe876"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport            509\n",
       "business         508\n",
       "politics         415\n",
       "tech             399\n",
       "entertainment    384\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data overview\n",
    "df[\"category\"].value_counts() \n",
    "#Return a Series containing counts of unique values.\n",
    "#The resulting object will be in descending order\n",
    "#so that the first element is the most frequently-occurring element.\n",
    "#Excludes NA values by default.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3FbD1_pedqz"
   },
   "source": [
    "#Creating Train and Test Datasets\n",
    "Note that the labels for test data will not be present in the dataset and hence they are mentioned as NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5s_HyqzgUL8"
   },
   "outputs": [],
   "source": [
    "# The last 10 rows in the csv file are query points, so loading them into test data.\n",
    "# And loading the reamining points to train_data for which labels are given.\n",
    "train_data = df.iloc[:-10]\n",
    "test_data = df.iloc[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "YZEIcpGHg40M",
    "outputId": "39211645-95e0-4bab-a06c-7966847aa1c3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>politics</td>\n",
       "      <td>teens  know little  of politics teenagers ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>lopez misses uk charity premiere jennifer lope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>business</td>\n",
       "      <td>christmas shoppers flock to tills shops all ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>tech</td>\n",
       "      <td>progress on new internet domains by early 2005...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>business</td>\n",
       "      <td>bush budget seeks deep cutbacks president bush...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2215 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           category                                               text\n",
       "0              tech  tv future in the hands of viewers with home th...\n",
       "1          business  worldcom boss  left books alone  former worldc...\n",
       "2             sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3             sport  yeading face newcastle in fa cup premiership s...\n",
       "4     entertainment  ocean s twelve raids box office ocean s twelve...\n",
       "...             ...                                                ...\n",
       "2210       politics  teens  know little  of politics teenagers ques...\n",
       "2211  entertainment  lopez misses uk charity premiere jennifer lope...\n",
       "2212       business  christmas shoppers flock to tills shops all ov...\n",
       "2213           tech  progress on new internet domains by early 2005...\n",
       "2214       business  bush budget seeks deep cutbacks president bush...\n",
       "\n",
       "[2215 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For train_data here the labels are in the column named \"category\".\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "t5w-_FJ3JEQ4",
    "outputId": "b7e36697-b937-47c9-cf74-71278a1ab83a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>NaN</td>\n",
       "      <td>junk e-mails on relentless rise spam traffic i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>NaN</td>\n",
       "      <td>top stars join us tsunami tv show brad pitt  r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>NaN</td>\n",
       "      <td>rings of steel combat net attacks gambling is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>NaN</td>\n",
       "      <td>davies favours gloucester future wales hooker ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>NaN</td>\n",
       "      <td>beijingers fume over parking fees choking traf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>NaN</td>\n",
       "      <td>cars pull down us retail figures us retail sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>NaN</td>\n",
       "      <td>kilroy unveils immigration policy ex-chatshow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>NaN</td>\n",
       "      <td>rem announce new glasgow concert us band rem h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>NaN</td>\n",
       "      <td>how political squabbles snowball it s become c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>NaN</td>\n",
       "      <td>souness delight at euro progress boss graeme s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     category                                               text\n",
       "2215      NaN  junk e-mails on relentless rise spam traffic i...\n",
       "2216      NaN  top stars join us tsunami tv show brad pitt  r...\n",
       "2217      NaN  rings of steel combat net attacks gambling is ...\n",
       "2218      NaN  davies favours gloucester future wales hooker ...\n",
       "2219      NaN  beijingers fume over parking fees choking traf...\n",
       "2220      NaN  cars pull down us retail figures us retail sal...\n",
       "2221      NaN  kilroy unveils immigration policy ex-chatshow ...\n",
       "2222      NaN  rem announce new glasgow concert us band rem h...\n",
       "2223      NaN  how political squabbles snowball it s become c...\n",
       "2224      NaN  souness delight at euro progress boss graeme s..."
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLwm7M7QSw1Y"
   },
   "source": [
    "#Custom  Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "BhoKEB1GhSn2"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from numpy import linalg as la\n",
    "\n",
    "def predictLabels (test_data):\n",
    "    \n",
    "    tfidf = TfidfVectorizer(ngram_range = (2,3), max_features = 4000,           #Generating vectorized train_data using sklearns built in tfidf vectorize\n",
    "                                                                min_df = 10)    #with bigrams & trigrams,max features to 4000 and mini document frequency to 10\n",
    "    train_vectors = tfidf.fit_transform(train_data.text)\n",
    "\n",
    "    num_hyperplanes = 5                                                         #Number of hyperplanes\n",
    "    k = 11                                                                      #11 nearest neighbours\n",
    "\n",
    "    np.random.seed(0)\n",
    "    hyperplanes = np.random.normal(0, 1, (num_hyperplanes,                      #Generating 5 normally distributed random hyperplanes with mean=0 & variance=1 \n",
    "                                          train_vectors.shape[1]))\n",
    "    a = np.arange(num_hyperplanes-1, -1, step = -1)                             #initializing binary values\n",
    "    power_of_two = 1 << a                                                       #Generating power of two, 1<<a = 1*2^a\n",
    "    score = find_dist(train_vectors, hyperplanes, power_of_two)                 #Calculating distances of training datapoints from hyperplanes\n",
    "    table = defaultdict(list)                                                   #Initializing dictionary with list of values\n",
    "    for i in range(len(score)):                                                 #Creating the dictionary while placing the points into their respective bins\n",
    "        table[score[i]].append(i)\n",
    "\n",
    "    Xq = tfidf.transform(test_data.text)                                        #Vectorizing the text in test data with TfidfVectorizer\n",
    "    Q_score = list(find_dist(Xq, hyperplanes, power_of_two))                    #Calculating distances of query points from hyperplanes\n",
    "\n",
    "    predicted_labels = []                                                      \n",
    "    for i in range(len(Q_score)):                                               #Finding predicted labels for the query points by looping through each datapoint\n",
    "        locality = []                                                          \n",
    "        locality = np.array(table[Q_score[i]])\n",
    "        cos_sim = []\n",
    "        for j in locality:                                                      #Finding cosine similarities of all the datapoints in the locality\n",
    "            cosine = (train_vectors[j].dot(Xq[i].T)).todense().item() / (la.norm(train_vectors[j].toarray()) * (la.norm(Xq[i].toarray())))\n",
    "            cos_sim.append(cosine)\n",
    "        argsorted_cos_sim = np.argsort(cos_sim)[::-1]                           #Sorting the similarities indices in descending order\n",
    "        neighbors = locality[argsorted_cos_sim[:k]]                             #Considering only the nearest k=11 neighbors\n",
    "        predictions = list(train_data.category[neighbors])                      #Predicting possible query points labels by using training data's labels\n",
    "        label = max(set(predictions), key = predictions.count)                  #Getting the label by maximum frequented possible labels\n",
    "        predicted_labels.append(label)                                          #Forming a list of labels of all the query points\n",
    "    return(predicted_labels)                                                    #and returning it to the main function\n",
    "\n",
    "def find_dist(vector, hyperplanes, power_of_two):                               \n",
    "    bin_bits = vector.dot(hyperplanes.T) <= 0                                   #generating binary bits 0 for the points on the -ve side and 1 for +ve of the hyperplanes                                                          \n",
    "    dec_val = bin_bits.dot(power_of_two)                                        #Converting the binary bits into corresponding decimal values\n",
    "    return dec_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-N_Xy3MV4iR3",
    "outputId": "7a247ad4-584b-4e15-e65b-60295fa24298"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** Success ******** Accuracy Achieved 90 %\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "## GRADER CELL: Do NOT Change this.\n",
    "# This cell will print \"Success\" if your implmentation of the computeTFIDF() is correct.\n",
    "# Else, it will print \"Failed\"\n",
    "###########################################\n",
    "import numpy as np\n",
    "\n",
    "# compute TF-IDF using the computeTFIDF() function\n",
    "Y_custom = np.array(predictLabels(test_data))\n",
    "\n",
    "# Reference grader array - DO NOT MODIFY IT\n",
    "Y_grader = np.array(['tech', 'entertainment', 'tech', 'sport', 'business', 'business', 'politics', 'entertainment', 'politics', 'sport'])\n",
    "\n",
    "#calculating accuracy by comparing Y_grader and Y_custom\n",
    "accuracy=np.sum(Y_grader==Y_custom)*10\n",
    "# compare Y_grader and Y_custom\n",
    "if accuracy>=80:\n",
    "  print(\"******** Success ********\",\"Accuracy Achieved\",accuracy,'%')\n",
    "else:\n",
    "  print(\"####### Failed #######\")\n",
    "  print(\"\\Y_grader = \\n\\n\", Y_grader)\n",
    "  print(\"\\n\",\"*\"*50)\n",
    "  print(\"\\Y_custom = \\n\\n\", Y_custom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-5B8AnQ6rEC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "My LSH from Scratch Assignment",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
